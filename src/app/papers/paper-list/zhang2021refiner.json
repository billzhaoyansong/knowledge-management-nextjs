{
  "title": "Refiner: a reliable incentive-driven federated learning system powered by blockchain",
  "authors": [
    "Zhebin Zhang",
    "Dajie Dong",
    "Yuhang Ma",
    "Yilong Ying",
    "Dawei Jiang",
    "Ke Chen",
    "Lidan Shou",
    "Gang Chen"
  ],
  "type": "technical",
  "year": "2021-07",
  "editing": false,
  "labels": [
    "federated learning",
    "reward",
    "punishment",
    "blockchain",
    "security",
    "smart contract",
    "privacy"
  ],
  "abstract": "Modern mobile applications often produce decentralized data, i.e., a huge amount of privacy-sensitive data distributed over a large number of mobile devices. Techniques for learning models from decentralized data must properly handle two natures of such data, namely privacy and massive engagement. Federated learning (FL) is a promising approach for such a learning task since the technique learns models from data without exposing privacy. However, traditional FL methods assume that the participating mobile devices are honest volunteers. This assumption makes traditional FL methods unsuitable for applications where two kinds of participants are engaged: 1) self-interested participants who, without economical stimulus, are reluctant to contribute their computing resources unconditionally, and 2) malicious participants who send corrupt updates to disrupt the learning process. This paper proposes Refiner, a reliable federated learning system for tackling the challenges introduced by massive engagements of self-interested and malicious participants. Refiner is built upon Ethereum, a public blockchain platform. To engage self-interested participants, we introduce an incentive mechanism which rewards each participant in terms of the amount of its training data and the performance of its local updates. To handle malicious participants, we propose an audit scheme which employs a committee of randomly chosen validators for punishing them with no reward and preclude corrupt updates from the global model. The proposed incentive and audit scheme is implemented with cryptocurrency and smart contract, two primitives offered by Ethereum. This paper demonstrates the main features of Refiner by training a digit classification model on the MNIST dataset.",
  "summaries": [
    "in the conventional FL framework, __[1] deploy a smart contract to audit the learning and reward process__, __[2] preserve privacy by deploying public-private key pair__, __[3] choose a committee of validators__ from clients using Algorand to evaluate local models' performance and prevent attacks, __[4] reward clients with cryptocurrencies__ based on the amount of data and the performance of local updates, __[5] punish malicious clients with no reward__"
  ],
  "systemModel": [],
  "techniques": [
    ""
  ],
  "experiments": [],
  "futureWorks": [],
  "comments": [],
  "doi": "10.14778/3476311.3476313",
  "id": "zhang2021refiner",
  "bibtex": "@article{zhang2021refiner, author = {Zhang, Zhebin and Dong, Dajie and Ma, Yuhang and Ying, Yilong and Jiang, Dawei and Chen, Ke and Shou, Lidan and Chen, Gang}, title = {Refiner: a reliable incentive-driven federated learning system powered by blockchain}, year = {2021}, issue_date = {July 2021}, publisher = {VLDB Endowment}, volume = {14}, number = {12}, issn = {2150-8097}, url = {https://doi-org.remotexs.ntu.edu.sg/10.14778/3476311.3476313}, doi = {10.14778/3476311.3476313}, abstract = {Modern mobile applications often produce decentralized data, i.e., a huge amount of privacy-sensitive data distributed over a large number of mobile devices. Techniques for learning models from decentralized data must properly handle two natures of such data, namely privacy and massive engagement. Federated learning (FL) is a promising approach for such a learning task since the technique learns models from data without exposing privacy. However, traditional FL methods assume that the participating mobile devices are honest volunteers. This assumption makes traditional FL methods unsuitable for applications where two kinds of participants are engaged: 1) self-interested participants who, without economical stimulus, are reluctant to contribute their computing resources unconditionally, and 2) malicious participants who send corrupt updates to disrupt the learning process. This paper proposes Refiner, a reliable federated learning system for tackling the challenges introduced by massive engagements of self-interested and malicious participants. Refiner is built upon Ethereum, a public blockchain platform. To engage self-interested participants, we introduce an incentive mechanism which rewards each participant in terms of the amount of its training data and the performance of its local updates. To handle malicious participants, we propose an audit scheme which employs a committee of randomly chosen validators for punishing them with no reward and preclude corrupt updates from the global model. The proposed incentive and audit scheme is implemented with cryptocurrency and smart contract, two primitives offered by Ethereum. This paper demonstrates the main features of Refiner by training a digit classification model on the MNIST dataset.}, journal = {Proc. VLDB Endow.}, month = {jul}, pages = {2659â€“2662}, numpages = {4} }"
}