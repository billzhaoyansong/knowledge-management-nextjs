{
  "title": "A Hierarchical Incentive Design Toward Motivating Participation in Coded Federated Learning",
  "authors": [
    "Jer Shyuan Ng",
    "Wei Yang Bryan Lim",
    "Zehui Xiong",
    "Xianbin Cao",
    "Dusit Niyato",
    "Cyril Leung",
    "Dong In Kim"
  ],
  "year": "2021-06",
  "labels": [
    "federated learning",
    "evolutionary game",
    "forward auction",
    "client mapping",
    "incentive mechanism",
    "multi-job",
    "architecture"
  ],
  "summaries": [
    "propose __a hierarchical system model__ where data owners sell data to FL workers, and model owners bid for services from FL workers",
    "interactions between data owners and FL workers are modeled as an evolutionary game where groups of data owners select FL workers to maximize self utility",
    "interactions between FL workers and model owners are presented as a forward auctioning game where model owners bid and a deep neural network is used to determine allocation of FL workers and corresponding payouts"
  ],
  "systemModel": [
    "a set $\\mathcal{I}=\\{1,...,i,...,I\\}$ of $I$ servers (model owners)",
    "a set of $\\mathcal{J}=\\{1,...,j,...,J\\}$ of $J$ workers (edge nodes)",
    "a set of $K$ sensing devices (data owners)",
    "data owners send privacy-preserved data to FL workers accordingly and receive rewards [see 1. Low-Level Evolutionary Game]",
    "FL workers pick model owners based on their bids and receive payments [see 2. Upper-Level Deep Learning Based Auction]"
  ],
  "motivation": [
    "To minimize the latency of the FL training tasks, coding techniques, which introduce redundant computations, can be used.",
    "Specifically for FL tasks, Coded Federated Learning (CFL) [9] is proposed to speed up the FL training process by assigning redundant computations to the FL server.",
    "In CFL, the edge nodes compute the partial gradients on a subset of their local datasets, instead of the entire dataset.",
    "Moreover, different from the traditional FL frameworks where the partial gradients are computed entirely by the edge nodes, the FL server performs an optimal amount of redundant partial gradient computations, given the composite parity data generated by the edge nodes.",
    "Upon completion of computations by both the FL server and edge nodes, the FL server combines the partial gradients computed by itself and the edge nodes to estimate the full gradient of the FL model.",
    "Since the edge nodes compute the partial gradients on a subset of their datasets, the computation latency is reduced and hence, minimizing the delay of the FL training.",
    "However, the issue of resource allocation is not well addressed in the literature.",
    "In particular, there is no motivation for the edge nodes to participate in the CFL tasks.",
    "A critical question that needs to be addressed by each edge node is “Given its amount of data, computation and communication capabilities, which FL server should it choose to train the FL model?”",
    "For the sensing devices that can contribute their data for the FL training, the question is “Which edge node should they contribute their data to in order to improve the accuracy of the FL model?”",
    "Incentive mechanisms are essential to encourage the participation of the edge nodes in the CFL tasks by offering them monetary rewards in exchange for their contribution of data and resources used in the FL training.",
    "The incentive mechanisms elicit the values of different entities for the resources, thereby allocating the resources to the entities that value them most."
  ],
  "questions": [
    "incentive mechanism in coded Federated Learning (CFL)"
  ],
  "techniques": [
    "1. Low-Level Evolutionary Game",
    [
      "Game settings:",
      [
        "Players: $J$ FL workers and $K$ data owners",
        "Population: data owners are divided into $Z$ populations and in each population $z$,",
        [
          "every data owner has the same privacy preference $\\varphi_z$",
          "and, every data owner has the same data samples $d_z$"
        ],
        "Strategy: each data owner selects an FL worker to join to achieve utility maximization",
        "Population share: the fraction of population $z$ that selects FL worker $j$ denoted by $0\\leq x_j^{(z)}\\leq 1$",
        [
          "$\\sum_{j=1}^{J} x_j^{(z)}=1$",
          "$\\mathbf{x}^{(z)}=[x_1^{(z)},...,x_J^{(z)}]$"
        ]
      ],
      "Data owners' utility",
      [
        "utility for population $z$: $u_j^{(z)}=\\mathcal{U}\\left(\\rho_j\\frac{x_j^{(z)}D_z}{\\sum_{z=1}^{Z}x_j^{(z)}D_z} - \\varphi_z\\epsilon_j \\right)$",
        [
          "$\\rho_j$: the reward pool offered by FL worker $j$",
          "$\\epsilon$: privacy budget",
          "$\\varphi_z \\epsilon_j$: privacy cost",
          "$\\mathcal{U}$: linear utility function indicating risk neurality of data owners"
        ]
      ],
      "Evolutionary algorithm",
      [
        "1. calculate the utility for current participation plan $\\mathbf{x}^{(z)}$",
        "2. update $\\mathbf{x}^{(z)}$ based on the utility from the last step, go back to step 1 unless the algorithm reaches the max predefined round"
      ]
    ],
    "2. Upper-Level Deep Learning Based Auction",
    [
      "2.1 each model owner $i$ offers a bid to each FL worker $i$: $\\alpha_j^i=\\eta_i - d_i +\\frac{1}{\\gamma_i}+\\frac{d_j^*}{d_j}+\\epsilon_j$",
      [
        "$\\eta_i$: data requirements (maybe accuracy requirements)",
        "$d_i$: training data quantity",
        "$\\gamma_i$: number of parity data generated (aka coding redundancy)",
        "$d_j^*$: optimal number of parity data to be generated by FL worker $j$",
        "$d_j$: number of data samples of FL worker $j$",
        "$\\epsilon_j$: privacy budget"
      ],
      "2.2 Deep learning based auction",
      [
        "2.2.1 map the input bid from $\\alpha_i^j$ to transformed bid $\\bar{\\alpha}_i^j$ with $\\phi_i^j$, which is a 2-layer feed forward network and consists of the min and max operators",
        "2.2.2 FL workers are allocated with a softmax function $g_i^j(\\bar{\\alpha}_i^j)=softmax_i^j(\\bar{\\alpha}_1^j,...,\\bar{\\alpha}_{I+1}^j;\\kappa)$",
        "2.2.3 payments are determined by ReLU activator $\\theta_{ij}^0 (\\bar{\\mathbf{\\alpha}}^j)=ReLU(\\max\\limits_{s\\neq i} \\bar{\\alpha}_s^j)$ and subsequently an inverse transform function $\\theta_i^j=\\phi_{ij}^{-1}\\left(\\theta_{ij}^0 (\\bar{\\mathbf{\\alpha}}^j)\\right)$",
        "training of both worker allocation network and payment determination network is by minimizing the objective loss function"
      ]
    ]
  ],
  "doi": "10.1109/JSAC.2021.3126057",
  "id": "ng2021hierarchical",
  "bibtex": "@article{ng2021hierarchical, title={A hierarchical incentive design toward motivating participation in coded federated learning}, author={Ng, Jer Shyuan and Lim, Wei Yang Bryan and Xiong, Zehui and Cao, Xianbin and Niyato, Dusit and Leung, Cyril and Kim, Dong In}, journal={IEEE Journal on Selected Areas in Communications}, volume={40}, number={1}, pages={359--375}, year={2021}, publisher={IEEE}}"
}