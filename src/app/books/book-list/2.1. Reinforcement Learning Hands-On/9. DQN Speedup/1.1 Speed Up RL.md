# DQN Speed up

- **Metrics**
  - _**FPS**_: frames the environment consume per second, indicating the speed of communicating with the environment
  - **_Wall Clock Time_**: the time it takes to run the code

---

- **N-Environment**
  - use several copies of the same environment
  - populate replay buffer with samples from all those environments and then sample a proportionally larger batch size on every training iteration

---

- **Playing and training in parallel**
  - can be effective in a very slow and heavy environment, so every step takes seconds of computations
  - <div style="display: flex; gap: 10px;">
    <div>
      <img style="width:75%;max-width:300px;" src="/books/Reinforcement Learning Hands-On/dqn seq.png" />
    </div>
    <div>
      <img style="width:75%;max-width:500px;" src="/books/Reinforcement Learning Hands-On/dqn parallel.png" />
    </div>
    </div>

---

- **Fine-tuning wrappers**
  - **_Motivation_**
    - While wrappers are often reused without modification, optimizing them can improve training speed and convergence (for Atari Environments).
  - **_Key Wrappers & Their Roles_**
    - `NoopResetEnv`: Introduces random NOOP actions at reset to avoid biased initial states.
    - `MaxAndSkipEnv`: Applies max-pooling over frames to reduce flickering (common in Atari games).
    - `EpisodicLifeEnv`: Treats each life as an episode, speeding up learning in games with multiple lives.
    - `FireResetEnv`: Forces a FIRE action at reset to start gameplay (avoids POMDP issues).
    - `WarpFrame`: Resizes frames to 84Ã—84 and converts to grayscale.
    - `ClipRewardEnv`: Normalizes rewards to [-1, 1] for consistency across games.
    - `FrameStack`: Stacks multiple frames (default: 4) to preserve temporal information (needed for Markov property).
  - _**Optimization Considerations**_
    - Default settings (e.g., 4-frame stacking) work for general Atari benchmarks but may not be optimal for specific games.
    - Performance tweaks:
      - Removing unnecessary wrappers (e.g., `NoopResetEnv` for stable games).
      - Simplifying `MaxAndSkipEnv` (e.g., skipping frames without max-pooling).
      - Reducing `FrameStack` size (e.g., 2 frames instead of 4).
    - Image processing optimizations:
      - Earlier, pillow-simd was faster than OpenCV for resizing, but modern OpenCV is now optimized.
      - Testing different scaling methods/libraries can still help.

---

- **Benchmarking**
  -
    | Step                      | FPS | $\Delta$FPS | Time, mins | $\Delta$Time |
    | ------------------------- | --- | ----------- | ---------- | ------------ |
    | Baseline                  | 229 | -           | 52.2       | -            |
    | Without `torch.no_grad()` | 219 | -4.3%       | 51.0       | -2.3%        |
    | 3 environments            | 395 | +72.5%      | 36.0       | -31.0%       |
    | Parallel version          | 290 | +26.6%      | 31.2       | -40.2%       |
    | Wrappers + 3 environments | 448 | +95.6%      | 47.4       | -9.2%        |
    | Wrappers + parallel       | 325 | +41.9%      | 30.0       | -42.5%       |