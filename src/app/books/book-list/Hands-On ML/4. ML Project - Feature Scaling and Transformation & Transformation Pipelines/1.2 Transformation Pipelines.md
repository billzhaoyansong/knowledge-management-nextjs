# 5.2 Transformation Pipelines

- the transformation pipelines can include _transformers_, _encoders_, and _imputers_
  
## Combine transformers

- option 1
  - the constructor takes a list of `name`/`estimator` pairs (2-tuples) defining a sequence of steps
    - `name`: anything you like as long as unique and does't contain double underscores
    - `estimator`: transformers

    ```python
    from sklearn.pipeline import Pipeline

    num_pipeline = Pipeline([
        ("impute", SimpleImputer(strategy="median")),
        ("standardize", StandardScaler()),
    ])
    ```

- option 2 (to ignore the name of transformers)

    ```python
    from sklearn.pipeline import make_pipeline

    num_pipeline = make_pipeline(SimpleImputer(strategy="median"), StandardScaler())
    ```

- to visualize pipelines in jupyter

    ```python
    import sklearn
    sklearn.â€‹set_config(display="diagram")
    num_pipeline
    ```

## Column transformer

- a single transformer capable of handling all columns, applying the appropriate transformations to each column

    ```python
    from sklearn.compose import ColumnTransformer
    from sklearn.compose import make_column_selector, make_column_transformer

    num_attribs = ["longitude", "latitude", "housing_median_age", "total_rooms",
                "total_bedrooms", "population", "households", "median_income"]
    cat_attribs = ["ocean_proximity"]

    cat_pipeline = make_pipeline(
        SimpleImputer(strategy="most_frequent"),
        OneHotEncoder(handle_unknown="ignore"))

    # option 1: create `ColumnTransformer` by specifying column names
    preprocessing = ColumnTransformer([
        ("num", num_pipeline, num_attribs),
        ("cat", cat_pipeline, cat_attribs),
    ])

    # option 2: create `ColumnTransformer` by specifying data types and ignoring transformer names
    preprocessing = make_column_transformer(
        (num_pipeline, make_column_selector(dtype_include=np.number)),
        (cat_pipeline, make_column_selector(dtype_include=object)),
    )

    # the final result
    housing_prepared = preprocessing.fit_transform(housing)
    ```

## Full code

```python
def column_ratio(X):
    return X[:, [0]] / X[:, [1]]

def ratio_name(function_transformer, feature_names_in):
    return ["ratio"]  # feature names out

def ratio_pipeline():
    return make_pipeline(
        SimpleImputer(strategy="median"),
        FunctionTransformer(column_ratio, feature_names_out=ratio_name),
        StandardScaler())

log_pipeline = make_pipeline(
    SimpleImputer(strategy="median"),
    FunctionTransformer(np.log, feature_names_out="one-to-one"),
    StandardScaler())
cluster_simil = ClusterSimilarity(n_clusters=10, gamma=1., random_state=42)
default_num_pipeline = make_pipeline(SimpleImputer(strategy="median"),
                                     StandardScaler())
preprocessing = ColumnTransformer([
        ("bedrooms", ratio_pipeline(), ["total_bedrooms", "total_rooms"]),
        ("rooms_per_house", ratio_pipeline(), ["total_rooms", "households"]),
        ("people_per_house", ratio_pipeline(), ["population", "households"]),
        ("log", log_pipeline, ["total_bedrooms", "total_rooms", "population",
                               "households", "median_income"]),
        ("geo", cluster_simil, ["latitude", "longitude"]),
        ("cat", cat_pipeline, make_column_selector(dtype_include=object)),
    ],
    remainder=default_num_pipeline)  # one column remaining: housing_median_age

housing_prepared = preprocessing.fit_transform(housing)
housing_prepared.shape
```