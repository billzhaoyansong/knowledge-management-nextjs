# 7.6 The ROC curve

- receiver operating characteristic (ROC) curve plots the true positive rate (another name for recall) against the false positive rate (FPR)
  - $FPR=\frac{FP}{FP+TN}$
  - One way to compare classifiers is to measure the area under the curve (AUC). A __perfect classifier__ will have a ROC AUC equal to $1$

```python
from sklearn.metrics import roc_curve, roc_auc_score

fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)

idx_for_threshold_at_90 = (thresholds <= threshold_for_90_precision).argmax()
tpr_90, fpr_90 = tpr[idx_for_threshold_at_90], fpr[idx_for_threshold_at_90]

plt.plot(fpr, tpr, linewidth=2, label="ROC curve")
plt.plot([fpr_90], [tpr_90], "ko", label="Threshold for 90% precision")
plt.show()

roc_auc_score(y_train_5, y_scores)
```
