# 13.4 Elastic Net Regression

- lastic net regression is a middle ground between ridge regression and lasso regression.
- cost function
  - $J(\bm{\theta})=\text{MSE}(\bm{\theta})+r\left(2\alpha\sum_{i=1}^n|\theta_i|\right)+(1-r)\left(\frac{\alpha}{m}\sum_{i=1}^n\theta^2_i\right)$
- **elastic net** vs **ridge** vs **lasso** vs **plain linear**
  - almost always preferable to have at least a little bit of regularization, so generally you should avoid plain linear regression
  - Ridge is a good default, but if you suspect that only a few features are useful, you should prefer lasso or elastic net because they tend to reduce the useless featuresâ€™ weights down to zero, as discussed earlier.
  - In general, elastic net is preferred over lasso because lasso may behave erratically when the number of features is greater than the number of training instances or when several features are strongly correlated.

```python
from sklearn.linear_model import ElasticNet
elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5)
elastic_net.fit(X, y)
elastic_net.predict([[1.5]]) # array([1.54333232])
```
