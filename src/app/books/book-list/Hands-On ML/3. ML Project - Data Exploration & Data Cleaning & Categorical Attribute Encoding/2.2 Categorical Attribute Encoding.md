# 4.3 Categorical Attribute Encoding

- transform categorical attributes into numerical attributes: most ML algorithms prefer to work with numbers

## Convert with `OrdinalEncoder`

- ML algorithms will assume that two nearby values are more similar than two distant values
- This may be fine in some cases (e.g., for ordered categories such as “bad”, “average”, “good”, and “excellent”), but it is obviously not the case for the ocean_proximity column

```python
from sklearn.preprocessing import OrdinalEncoder

housing_cat = housing[["ocean_proximity"]]

# check the corresponding relationships between ordinal number and categorical attributes:
#   ordinal_encoder.categories_
ordinal_encoder = OrdinalEncoder()
housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)
```

## Convert with __one-hot encoding__

- a large number of possible categories (e.g., country code, profession, species) results in a large number of input features, leading to slow training and degrading performance
- solution
  - replace the categorical input with useful numerical features related to the categories, or
  - use one of the encoders provided by the category_encoders package on [GitHub](https://github.com/scikit-learn-contrib/category_encoders), or
  - when dealing with neural networks, you can replace each category with a learnable, low-dimensional vector called an __embedding__

```python
from sklearn.preprocessing import OneHotEncoder

# add sparse=False if you want to get a regular numpy array
cat_encoder = OneHotEncoder()

# housing_cat_1hot will be a sparse matrix which saves plenty of memory and speed up computations
# to convert it to a dense numpy array, call housing_cat_1hot.toarray()
housing_cat_1hot = cat_encoder.fit_transform(housing_cat)

# use a dataframe to wrap the output
df_output = pd.DataFrame(cat_encoder.transform(df_test_unknown),
                         columns=cat_encoder.get_feature_names_out(),
                         index=df_test_unknown.index)
```
