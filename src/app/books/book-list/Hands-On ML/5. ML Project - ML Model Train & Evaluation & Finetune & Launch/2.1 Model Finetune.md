# 6.3 Model Finetune

- before model finetuning, many other models should be tried out from various categories of ML algorithms (e.g. several support vector machines with different kernels, and possibly a neural network) to __shortlist a few (two to five) promising models__.

## (1) Grid search

```python
from sklearn.model_selection import GridSearchCV

preprocessing = ColumnTransformer([
        ("bedrooms", ratio_pipeline(), ["total_bedrooms", "total_rooms"]),
        ("rooms_per_house", ratio_pipeline(), ["total_rooms", "households"]),
        ("people_per_house", ratio_pipeline(), ["population", "households"]),
        ("log", log_pipeline, ["total_bedrooms", "total_rooms", "population",
                               "households", "median_income"]),
        ("geo", cluster_simil, ["latitude", "longitude"]),
        ("cat", cat_pipeline, make_column_selector(dtype_include=object)),
    ],
    remainder=default_num_pipeline)

full_pipeline = Pipeline([
    ("preprocessing", preprocessing),
    ("random_forest", RandomForestRegressor(random_state=42)),
])

param_grid = [
    {'preprocessing__geo__n_clusters': [5, 8, 10],
     'random_forest__max_features': [4, 6, 8]},
    {'preprocessing__geo__n_clusters': [10, 15],
     'random_forest__max_features': [6, 8, 10]},
]
grid_search = GridSearchCV(full_pipeline, param_grid, cv=3,
                           scoring='neg_root_mean_squared_error')
grid_search.fit(housing, housing_labels)

# retrieve the results
cv_res = pd.DataFrame(grid_search.cv_results_)
cv_res.sort_values(by="mean_test_score", ascending=False, inplace=True)
cv_res.head()
```

- mechanisms behind `GridSearch`:
  1. for the first dictionary in `para_grid`, `GridSearchCV` will first evaluate all $3 \times 3 = 9$ combinations of `n_clusters` and `max_features` hyperparameter values
     - when Scikit-Learn sees `preprocessing__geo__n_clusters`, it splits this string at the double underscores
     - looks for an estimator named `preprocessing` in the pipeline and finds the preprocessing ColumnTransformer
     - looks for a transformer named `geo` inside this ColumnTransformer and finds the ClusterSimilarity transformer we used on the latitude and longitude attributes
     - finds this transformer’s `n_clusters` hyperparameter
  2. for the second dictionary in `para_grid`, `GridSearchCV` will first evaluate all $2 \times 3 = 6$ combinations
  3. $3$ times per combination because of 3-fold cross validation
  4. in total, there will be $(9+6) \times 3 = 45$ rounds of training
- note: If `GridSearchCV` is initialized with `refit=True` (which is the default), then _once it finds the best estimator using cross-validation, it retrains it on the whole training set_.

## (2) Randomized search

- `RandomizedSearchCV` is often __preferable__, especially when the hyperparameter search space is large
- benefits of `RandomizedSearchCV`:
  - more suitable for continuous hyperparameters
  - a hyperparameter that does not actually make much difference will not make any difference in randomized search
  - randomized search can run the number of iterations you specified

    ```python
    from sklearn.model_selection import RandomizedSearchCV
    from scipy.stats import randint

    param_distribs = {'preprocessing__geo__n_clusters': randint(low=3, high=50),
                    'random_forest__max_features': randint(low=2, high=20)}

    rnd_search = RandomizedSearchCV(
        full_pipeline, param_distributions=param_distribs, n_iter=10, cv=3,
        scoring='neg_root_mean_squared_error', random_state=42)

    rnd_search.fit(housing, housing_labels)
    ```

## (3) Halving seach

- Scikit-Learn also has `HalvingRandomSearchCV` and `HalvingGridSearchCV` hyperparameter search classes to _use the computational resources more efficiently_
  1. in the first round, many hyperparameter combinations (called “candidates”) are generated with _limited resources_ (i.e. a small part of the training set, reducing the number of training iterations)
  2. only the best ones go on to the second round, where they are allowed more resources to compete
  3. After several rounds, the final candidates are evaluated using full resources.

## (4) Emsemble methods

- combine the models that perform best

## (5) Analyzing the best models and errors

```python
final_model = rnd_search.best_estimator_  # includes preprocessing
feature_importances = final_model["random_forest"].feature_importances_
feature_importances.round(2)

sorted(zip(feature_importances,
            final_model["preprocessing"].get_feature_names_out()),
            reverse=True)
```

- With this information, you may want to try dropping some of the less useful features
- ensure that your model not only works well on average, but also on all categories of districts

## (6) Evaluate on test set

```python
X_test = strat_test_set.drop("median_house_value", axis=1)
y_test = strat_test_set["median_house_value"].copy()

final_predictions = final_model.predict(X_test)

final_rmse = mean_squared_error(y_test, final_predictions, squared=False)

# the prediction error is roughly 41424
print(final_rmse)  # 41424.40026462184

from scipy import stats
confidence = 0.95
squared_errors = (final_predictions - y_test) ** 2
confidence_interval = np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,
                         loc=squared_errors.mean(),
                         scale=stats.sem(squared_errors)))

# 95% of errors reside in this interval
print(confidence_interval) #array([39275.40861216, 43467.27680583])
```