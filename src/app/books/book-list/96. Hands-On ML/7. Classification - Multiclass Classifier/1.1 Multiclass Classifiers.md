# 8.1 Multiclass Classifiers

- Some Scikit-learn classifiers are capable of handling multiple classes natively
  - e.g. `LogisticRegression`, `RandomForestClassifier`, `GaussianNB`, and neural networks
- binary classifiers can be adapted into handling multiple classes with OvR or OvO strategies

## (1) Strategies used by binary classifiers

- __one-versus-the-rest (OvR), or one-versus-all (OvA)__
  - e.g. for MNIST:
    - train 10 (0-9) binary classifiers, one for each digit 
      - 0-detector: classify 0 and non-0
      - 1-detector: classify 1 and non-1
      - $\vdots$
      - 9-detector: classify 9 and non-9
    - when you want to classify an image, you get the decision score from each classifier for that image and you select the class whose classifier outputs the highest score
  - _preferred for most_ binary classification algorithms
- __one-versus-one (OvO)__
  - e.g. for MNIST:
    - train a binary classifier for every pair of digits, totally $\frac{N \times (N-1)}{2}$ ($\frac{10 \times 9}{2}=45$) binary classifiers
      - 0-1 classifier
      - 0-2 classifier
      - $\vdots$
      - 8-9 classifier
    - When you want to classify an image, you have to run the image through all 45 classifiers and see which class wins the most duels
  - main _advantage_ of OvO: classifier only needs to be trained on the part of the training set containing the two classes
  - _preferred for some algorithms that scale poorly_ with the size of the training set, e.g. support vector machine classifiers

## (2) Classifiers

- Scikit-learn 

```python
from sklearn.svm import SVC
from sklearn.multiclass import OneVsRestClassifier

# ======
# option1
# SVC is a binary classifier
# but Scikit learn will automatically detect for multiclass task
# and decide the strategy (OvR or OvO)
svm_clf = SVC(random_state=42)
svm_clf.fit(X_train[:2000], y_train[:2000])

# predict a sample
print(svm_clf.predict([some_digit]))

# get the scores of this sample
some_digit_scores = svm_clf.decision_function([some_digit])
print(some_digit_scores.round(2))

# find the class index with the highest score
# print the class name of this index
class_id = some_digit_scores.argmax()
svm_clf.classes_[class_id]

# ======
# option2: to force to use OvR
ovr_clf = OneVsRestClassifier(SVC(random_state=42))
ovr_clf.fit(X_train[:2000], y_train[:2000])
print(ovr_clf.predict([some_digit]))

# ======
# option3:
sgd_clf = SGDClassifier(random_state=42)
sgd_clf.fit(X_train, y_train)
print(sgd_clf.predict([some_digit]))
print(sgd_clf.decision_function([some_digit]).round())
print(cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring="accuracy"))
```
