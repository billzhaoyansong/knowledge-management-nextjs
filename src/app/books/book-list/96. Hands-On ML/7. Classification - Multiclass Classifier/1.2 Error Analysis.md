# 8.2 Error Analysis

## (1) Confusion Matrix

```python
from sklearn.metrics import ConfusionMatrixDisplay

y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)

# confusion matrix default
ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)
plt.show() # refer to "Confusion matrix"

# confusion matrix normalized by row (#true labels)
ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,
                                        normalize="true", values_format=".0%")
plt.show() # refer to "CM normalized by row"

# errors normalized by row
sample_weight = (y_train_pred != y_train)
ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,
                                        sample_weight=sample_weight,
                                        normalize="true", values_format=".0%")
plt.show() # refer to "Errors normalized by row"

# errors normalized by column
ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred,
                                        sample_weight=sample_weight,
                                        normalize="pred", values_format=".0%")
plt.show() # refer to "Errors normalized by column"
```

<!-- ![alt text](cm-1.png) -->
<img width="80%" src="books\Hands-On ML\cm-1.png"/>

<img width="80%" src="books\Hands-On ML\cm-2.png"/>

- analyze confusion matrix, e.g.
  - reducing the false 8s, by:
    - gather more training data for digits that look like 8s but are not
    - engineer new features
    - preprocess the images to make some patterns

## (2) Individual error analysis

- as '3' and '5' are very common misclassified labels in the confusion matrix, you can draw the confusion matrix of individuals for further analysis (similarly, you can choose '6', '8')

```python
cl_a, cl_b = '3', '5'
X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]
X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]
X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]
X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]
```

<details><summary>code to draw the image</summary>

```python
# extra code – this cell generates and saves Figure 3–11
size = 5
pad = 0.2
plt.figure(figsize=(size, size))
for images, (label_col, label_row) in [(X_ba, (0, 0)), (X_bb, (1, 0)),
                                       (X_aa, (0, 1)), (X_ab, (1, 1))]:
    for idx, image_data in enumerate(images[:size*size]):
        x = idx % size + label_col * (size + pad)
        y = idx // size + label_row * (size + pad)
        plt.imshow(image_data.reshape(28, 28), cmap="binary",
                   extent=(x, x + 1, y, y + 1))
plt.xticks([size / 2, size + pad + size / 2], [str(cl_a), str(cl_b)])
plt.yticks([size / 2, size + pad + size / 2], [str(cl_b), str(cl_a)])
plt.plot([size + pad / 2, size + pad / 2], [0, 2 * size + pad], "k:")
plt.plot([0, 2 * size + pad], [size + pad / 2, size + pad / 2], "k:")
plt.axis([0, 2 * size + pad, 0, 2 * size + pad])
plt.xlabel("Predicted label")
plt.ylabel("True label")
save_fig("error_analysis_digits_plot")
plt.show()
```

</details>

<img width="50%" src="books\Hands-On ML\individual-error.png"/>

- The main difference between 3s and 5s is the position of the small line that joins the top line to the bottom arc.
- If you draw a 3 with the junction slightly shifted to the left, the classifier might classify it as a 5, and vice versa.
- solution: 
  - _augmenting_ the training set _with slightly shifted and rotated variants_ of the training images (also called _data augmentation_)