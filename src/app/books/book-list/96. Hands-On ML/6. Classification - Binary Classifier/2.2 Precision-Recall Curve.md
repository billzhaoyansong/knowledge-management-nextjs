# 7.5 The Precision-Recall Curve (PRC)

- `SGDClassifier` uses a threshold to decide the predicted positives
  - the higher the threshold
    - the actual positives will account for a higher propotion of predicted positives => high precision
    - but many actual positives will be classified into predicted negatives => low recall
  - the lower the threshold
    - many false positives will be classified as predicted positive => low precision
    - but the more actual positives will fall into predicted positives => high recall.
- By default, the threshold in `SGDClassifier` is set to 0, but you can adjust it if needed.

    ```python
    # specify that you want to return decision scores instead of predictions
    from sklearn.metrics import precision_recall_curve

    y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,
                                method="decision_function")
    precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)

    plt.plot(recalls, precisions, linewidth=2, label="Precision/Recall curve")
    [...]  # beautify the figure: add labels, grid, legend, arrow, and text
    plt.show()

    # find the threshold for 90% precision
    idx_for_90_precision = (precisions >= 0.90).argmax()
    threshold_for_90_precision = thresholds[idx_for_90_precision]
    print(threshold_for_90_precision)

    y_train_pred_90 = (y_scores >= threshold_for_90_precision)
    precision_at_90_precision = precision_score(y_train_5, y_train_pred_90)
    recall_at_90_precision = recall_score(y_train_5, y_train_pred_90)
    ```